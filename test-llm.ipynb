{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import GPT4All\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.chains import AnalyzeDocumentChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 18 key-value pairs and 237 tensors from /home/aadarsh/src/llm-sih-test/orca-mini-3b.q4_0.gguf (version GGUF V1 (support until nov 2023))\n",
      "llama_model_loader: - tensor    0:                token_embd.weight q4_0     [  3200, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor    1:               output_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    2:                    output.weight q4_0     [  3200, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor    3:              blk.0.attn_q.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor    4:              blk.0.attn_k.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor    5:              blk.0.attn_v.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor    6:         blk.0.attn_output.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor    7:           blk.0.attn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    8:            blk.0.ffn_gate.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor    9:            blk.0.ffn_down.weight q4_0     [  8640,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   10:              blk.0.ffn_up.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor   11:            blk.0.ffn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   12:              blk.1.attn_q.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   13:              blk.1.attn_k.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   14:              blk.1.attn_v.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   15:         blk.1.attn_output.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   16:           blk.1.attn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   17:            blk.1.ffn_gate.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor   18:            blk.1.ffn_down.weight q4_0     [  8640,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   19:              blk.1.ffn_up.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor   20:            blk.1.ffn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   21:              blk.2.attn_q.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   22:              blk.2.attn_k.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   23:              blk.2.attn_v.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   24:         blk.2.attn_output.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   25:           blk.2.attn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   26:            blk.2.ffn_gate.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor   27:            blk.2.ffn_down.weight q4_0     [  8640,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   28:              blk.2.ffn_up.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor   29:            blk.2.ffn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   30:              blk.3.attn_q.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   31:              blk.3.attn_k.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   32:              blk.3.attn_v.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   33:         blk.3.attn_output.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   34:           blk.3.attn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   35:            blk.3.ffn_gate.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor   36:            blk.3.ffn_down.weight q4_0     [  8640,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   37:              blk.3.ffn_up.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor   38:            blk.3.ffn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   39:              blk.4.attn_q.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   40:              blk.4.attn_k.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   41:              blk.4.attn_v.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   42:         blk.4.attn_output.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   43:           blk.4.attn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   44:            blk.4.ffn_gate.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor   45:            blk.4.ffn_down.weight q4_0     [  8640,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   46:              blk.4.ffn_up.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor   47:            blk.4.ffn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   48:              blk.5.attn_q.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   49:              blk.5.attn_k.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   50:              blk.5.attn_v.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   51:         blk.5.attn_output.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   52:           blk.5.attn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   53:            blk.5.ffn_gate.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor   54:            blk.5.ffn_down.weight q4_0     [  8640,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   55:              blk.5.ffn_up.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor   56:            blk.5.ffn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   57:              blk.6.attn_q.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   58:              blk.6.attn_k.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   59:              blk.6.attn_v.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   60:         blk.6.attn_output.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   61:           blk.6.attn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   62:            blk.6.ffn_gate.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor   63:            blk.6.ffn_down.weight q4_0     [  8640,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   64:              blk.6.ffn_up.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor   65:            blk.6.ffn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   66:              blk.7.attn_q.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   67:              blk.7.attn_k.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   68:              blk.7.attn_v.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   69:         blk.7.attn_output.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   70:           blk.7.attn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   71:            blk.7.ffn_gate.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor   72:            blk.7.ffn_down.weight q4_0     [  8640,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   73:              blk.7.ffn_up.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor   74:            blk.7.ffn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   75:              blk.8.attn_q.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   76:              blk.8.attn_k.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   77:              blk.8.attn_v.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   78:         blk.8.attn_output.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   79:           blk.8.attn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   80:            blk.8.ffn_gate.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor   81:            blk.8.ffn_down.weight q4_0     [  8640,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   82:              blk.8.ffn_up.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor   83:            blk.8.ffn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   84:              blk.9.attn_q.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   85:              blk.9.attn_k.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   86:              blk.9.attn_v.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   87:         blk.9.attn_output.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   88:           blk.9.attn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   89:            blk.9.ffn_gate.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor   90:            blk.9.ffn_down.weight q4_0     [  8640,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   91:              blk.9.ffn_up.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor   92:            blk.9.ffn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   93:             blk.10.attn_q.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   94:             blk.10.attn_k.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   95:             blk.10.attn_v.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   96:        blk.10.attn_output.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor   97:          blk.10.attn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   98:           blk.10.ffn_gate.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor   99:           blk.10.ffn_down.weight q4_0     [  8640,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  100:             blk.10.ffn_up.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor  101:           blk.10.ffn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  102:             blk.11.attn_q.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  103:             blk.11.attn_k.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  104:             blk.11.attn_v.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  105:        blk.11.attn_output.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  106:          blk.11.attn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  107:           blk.11.ffn_gate.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor  108:           blk.11.ffn_down.weight q4_0     [  8640,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  109:             blk.11.ffn_up.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor  110:           blk.11.ffn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  111:             blk.12.attn_q.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  112:             blk.12.attn_k.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  113:             blk.12.attn_v.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  114:        blk.12.attn_output.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  115:          blk.12.attn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  116:           blk.12.ffn_gate.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor  117:           blk.12.ffn_down.weight q4_0     [  8640,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  118:             blk.12.ffn_up.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor  119:           blk.12.ffn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  120:             blk.13.attn_q.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  121:             blk.13.attn_k.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  122:             blk.13.attn_v.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  123:        blk.13.attn_output.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  124:          blk.13.attn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  125:           blk.13.ffn_gate.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor  126:           blk.13.ffn_down.weight q4_0     [  8640,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  127:             blk.13.ffn_up.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor  128:           blk.13.ffn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  129:             blk.14.attn_q.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  130:             blk.14.attn_k.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  131:             blk.14.attn_v.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  132:        blk.14.attn_output.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  133:          blk.14.attn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  134:           blk.14.ffn_gate.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor  135:           blk.14.ffn_down.weight q4_0     [  8640,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  136:             blk.14.ffn_up.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor  137:           blk.14.ffn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  138:             blk.15.attn_q.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  139:             blk.15.attn_k.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  140:             blk.15.attn_v.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  141:        blk.15.attn_output.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  142:          blk.15.attn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  143:           blk.15.ffn_gate.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor  144:           blk.15.ffn_down.weight q4_0     [  8640,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  145:             blk.15.ffn_up.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor  146:           blk.15.ffn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  147:             blk.16.attn_q.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  148:             blk.16.attn_k.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  149:             blk.16.attn_v.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  150:        blk.16.attn_output.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  151:          blk.16.attn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  152:           blk.16.ffn_gate.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor  153:           blk.16.ffn_down.weight q4_0     [  8640,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  154:             blk.16.ffn_up.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor  155:           blk.16.ffn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  156:             blk.17.attn_q.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  157:             blk.17.attn_k.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  158:             blk.17.attn_v.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  159:        blk.17.attn_output.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  160:          blk.17.attn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  161:           blk.17.ffn_gate.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor  162:           blk.17.ffn_down.weight q4_0     [  8640,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  163:             blk.17.ffn_up.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor  164:           blk.17.ffn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  165:             blk.18.attn_q.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  166:             blk.18.attn_k.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  167:             blk.18.attn_v.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  168:        blk.18.attn_output.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  169:          blk.18.attn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  170:           blk.18.ffn_gate.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor  171:           blk.18.ffn_down.weight q4_0     [  8640,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  172:             blk.18.ffn_up.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor  173:           blk.18.ffn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  174:             blk.19.attn_q.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  175:             blk.19.attn_k.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  176:             blk.19.attn_v.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  177:        blk.19.attn_output.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  178:          blk.19.attn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  179:           blk.19.ffn_gate.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor  180:           blk.19.ffn_down.weight q4_0     [  8640,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  181:             blk.19.ffn_up.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor  182:           blk.19.ffn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  183:             blk.20.attn_q.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  184:             blk.20.attn_k.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  185:             blk.20.attn_v.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  186:        blk.20.attn_output.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  187:          blk.20.attn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  188:           blk.20.ffn_gate.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor  189:           blk.20.ffn_down.weight q4_0     [  8640,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  190:             blk.20.ffn_up.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor  191:           blk.20.ffn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  192:             blk.21.attn_q.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  193:             blk.21.attn_k.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  194:             blk.21.attn_v.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  195:        blk.21.attn_output.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  196:          blk.21.attn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  197:           blk.21.ffn_gate.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor  198:           blk.21.ffn_down.weight q4_0     [  8640,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  199:             blk.21.ffn_up.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor  200:           blk.21.ffn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  201:             blk.22.attn_q.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  202:             blk.22.attn_k.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  203:             blk.22.attn_v.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  204:        blk.22.attn_output.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  205:          blk.22.attn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  206:           blk.22.ffn_gate.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor  207:           blk.22.ffn_down.weight q4_0     [  8640,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  208:             blk.22.ffn_up.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor  209:           blk.22.ffn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  210:             blk.23.attn_q.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  211:             blk.23.attn_k.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  212:             blk.23.attn_v.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  213:        blk.23.attn_output.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  214:          blk.23.attn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  215:           blk.23.ffn_gate.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor  216:           blk.23.ffn_down.weight q4_0     [  8640,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  217:             blk.23.ffn_up.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor  218:           blk.23.ffn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  219:             blk.24.attn_q.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  220:             blk.24.attn_k.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  221:             blk.24.attn_v.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  222:        blk.24.attn_output.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  223:          blk.24.attn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  224:           blk.24.ffn_gate.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor  225:           blk.24.ffn_down.weight q4_0     [  8640,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  226:             blk.24.ffn_up.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor  227:           blk.24.ffn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  228:             blk.25.attn_q.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  229:             blk.25.attn_k.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  230:             blk.25.attn_v.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  231:        blk.25.attn_output.weight q4_0     [  3200,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  232:          blk.25.attn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  233:           blk.25.ffn_gate.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor  234:           blk.25.ffn_down.weight q4_0     [  8640,  3200,     1,     1 ]\n",
      "llama_model_loader: - tensor  235:             blk.25.ffn_up.weight q4_0     [  3200,  8640,     1,     1 ]\n",
      "llama_model_loader: - tensor  236:           blk.25.ffn_norm.weight f32      [  3200,     1,     1,     1 ]\n",
      "llama_model_loader: - kv   0:                       general.architecture str     \n",
      "llama_model_loader: - kv   1:                               general.name str     \n",
      "llama_model_loader: - kv   2:                        general.description str     \n",
      "llama_model_loader: - kv   3:                       llama.context_length u32     \n",
      "llama_model_loader: - kv   4:                     llama.embedding_length u32     \n",
      "llama_model_loader: - kv   5:                          llama.block_count u32     \n",
      "llama_model_loader: - kv   6:                  llama.feed_forward_length u32     \n",
      "llama_model_loader: - kv   7:                 llama.rope.dimension_count u32     \n",
      "llama_model_loader: - kv   8:                 llama.attention.head_count u32     \n",
      "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32     \n",
      "llama_model_loader: - kv  10:     llama.attention.layer_norm_rms_epsilon f32     \n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str     \n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr     \n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr     \n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr     \n",
      "llama_model_loader: - kv  15:            tokenizer.ggml.unknown_token_id u32     \n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32     \n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32     \n",
      "llama_model_loader: - type  f32:   53 tensors\n",
      "llama_model_loader: - type q4_0:  184 tensors\n",
      "llm_load_print_meta: format         = GGUF V1 (support until nov 2023)\n",
      "llm_load_print_meta: arch           = llama\n",
      "llm_load_print_meta: vocab type     = SPM\n",
      "llm_load_print_meta: n_vocab        = 32000\n",
      "llm_load_print_meta: n_merges       = 0\n",
      "llm_load_print_meta: n_ctx_train    = 2048\n",
      "llm_load_print_meta: n_ctx          = 2048\n",
      "llm_load_print_meta: n_embd         = 3200\n",
      "llm_load_print_meta: n_head         = 32\n",
      "llm_load_print_meta: n_head_kv      = 32\n",
      "llm_load_print_meta: n_layer        = 26\n",
      "llm_load_print_meta: n_rot          = 100\n",
      "llm_load_print_meta: n_gqa          = 1\n",
      "llm_load_print_meta: f_norm_eps     = 1.0e-05\n",
      "llm_load_print_meta: f_norm_rms_eps = 5.0e-06\n",
      "llm_load_print_meta: n_ff           = 8640\n",
      "llm_load_print_meta: freq_base      = 10000.0\n",
      "llm_load_print_meta: freq_scale     = 1\n",
      "llm_load_print_meta: model type     = 3B\n",
      "llm_load_print_meta: model ftype    = mostly Q4_0 (guessed)\n",
      "llm_load_print_meta: model size     = 3.43 B\n",
      "llm_load_print_meta: general.name   = orca-mini-3b.ggmlv3.q4_0.bin\n",
      "llm_load_print_meta: BOS token = 1 '<s>'\n",
      "llm_load_print_meta: EOS token = 2 '</s>'\n",
      "llm_load_print_meta: UNK token = 0 '<unk>'\n",
      "llm_load_print_meta: LF token  = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.08 MB\n",
      "llm_load_tensors: mem required  = 1838.74 MB (+  650.00 MB per state)\n",
      ".................................................................................................\n",
      "llama_new_context_with_model: kv self size  =  650.00 MB\n",
      "llama_new_context_with_model: compute buffer total size =  148.22 MB\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 1 | AVX512_VNNI = 1 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/aadarsh/.cache/gpt4all/orca-mini-3b.ggmlv3.q4_0.bin\"\n",
    "model_path2 = \"/home/aadarsh/src/llm-sih-test/orca-mini-3b.q4_0.gguf\"\n",
    "\n",
    "# llm = GPT4All(model=model_path, max_tokens=2048, n_predict=4096)\n",
    "llm = LlamaCpp(model_path=model_path2, n_ctx=2048, n_gpu_layers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_text1 = \"\"\"\n",
    "Manchester United have reportedly got the greenlight from Chelsea to sign Marc Cucurella on loan, and now have the choice between him and two other options.\n",
    "\n",
    "While it’s not been totally convincing, United’s season has started well, with two wins from their first three games this season. Injuries could hinder that progress though, with the defence being weakened at the moment.\n",
    "\n",
    "Specifically the left side of the defence, as Luke Shaw has joined fellow left-back Tyrell Malacia in spending a period on the sidelines after sustaining an injury.\n",
    "\n",
    "Erik ten Hag wants to ensure his side don’t suffer as a result, and has identified Chelsea defender Cucurella as a somewhat surprising deputy for those men.\n",
    "\n",
    "Transfer insider Fabrizio Romano has given an update on that situation, and it’s a positive one for United. He states the Blues ‘are open to letting Cucurella leave on loan’.\n",
    "\n",
    "They’ll allow the Spaniard to make the short-term switch to Old Trafford if they receive a loan fee and United cover his salary.\n",
    "\n",
    "The ball is in United’s court, and they could easily zero in on Cucurella, but they apparently have ‘three options’ for a new left-back, so will have to decide between the Chelsea outcast and two other men.\n",
    "\n",
    "One of those is reportedly Sergio Reguilon, given he’s a specialist left-back who is seemingly on the market, after Tottenham loaned him out last season and are yet to play him in this campaign.\n",
    "\n",
    "Moves for either men might come as a bit of a shock. Neither has played this term, and Cucurella missed the back end of last season through injury, and never truly nailed down a spot at Chelsea thanks to the presence of Ben Chilwell.\n",
    "\n",
    "But given United will only need the left-back until one of Shaw and Malacia is back, there’s only going to be a finite number of players they can get. Star players won’t be available on loan, so they’ll have to choose from limited options.\n",
    "\n",
    "\n",
    "Cucurella performed very well at Brighton before failing to find his feet at Chelsea. But he’s still shown that he’s an impactful player, and would not be massively out of place at United for a short time.\n",
    "\n",
    "Given there’s not long left of the window, United will have to make a decision soon on whether to take him or one of their other options.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_paper = \"\"\"\n",
    "Optimizing Diabetes Mellitus Classification using \n",
    "Deep Neural Networks on the PIMA Indians Dataset\n",
    "Abstract: Diabetes is a chronic illness that affects a significant number of individuals worldwide. Survey reports that the Pima Indians have one of the highest prevalence of diabetes mellitus globally. This study analyzes the Pima Indians Diabetes Dataset which contains diagnostic measurements of 768 Pima Indian women. Though prior research has predominantly employed several predictive models such as SVM, NB, DT, and RF classifiers for predicting diabetes in the PIMA Indians Dataset, all these techniques have been identified with some limitations. This indicates a need for a more accurate predictor and a scope for further study. Hence, this study proposes a Deep Neural Network (DNN) model on the PIMA Indians Dataset. This study shows that the proposed DNN model performs better (81.72%) when compared to other popularly used ML classifiers. Our findings suggest that DNNs are highly effective supervised learning algorithms that can be extended to other fields in medical research.\n",
    "Keywords: Deep Neural Networks, Deep Learning, Machine Learning, Diabetes Mellitus, PIMA Indians.\n",
    "1\tIntroduction\n",
    "Diabetes mellitus is a chronic metabolic condition that results in high blood sugar levels due to the body's inability to make or use insulin. [1] It is associated with various health complications such as cardiovascular disease, kidney failure, and stroke. Diabetes prediction is crucial because early identification and intervention can prevent or delay complications. [2] However, we currently lack an accurate predictor as the development of diabetes is influenced by a complex interplay of genetic, environmental, and lifestyle factors, making it difficult to predict with high accuracy.\n",
    "The Pima Indian population has been extensively studied as they have one of the highest prevalence of diabetes mellitus in the world. [3] The Pima Indians of Arizona have a genetic predisposition to insulin resistance and diabetes mellitus, making them an ideal population for studying the disease's underlying mechanisms. [4] The Pima Indians Diabetes Dataset is a well-known dataset several researchers have used to develop and evaluate machine learning models for predicting diabetes.\n",
    "Prior research has predominantly employed several predictive models such as Support Vector Machines (SVMs) and Naive Bayes (NB) classifiers separately [5], for this classification task, which are identified with certain limitations. The extant literature indicates a need for an accurate and better predictor. Hence, the primary aim of this study is to apply a Deep Neural Network and compare its performance with other popular ML techniques such as SVM, KNN, Gaussian Naïve Bayes and Logistic Regression. Our proposed method for predicting diabetes involves a data preprocessing pipeline, which includes exploratory data analysis, outlier removal using the Z Score and Inter Quartile Range method and missing data imputation. The DNN model achieves an accuracy of 81.72%, which surpasses the performance of other classifiers. Our prediction model has significant potential in the medical field as a valuable tool for predicting diabetes and helps prevent long-term complications associated with diabetes.\n",
    "The paper is structured in the following manner: The current section deals with the introduction. The second section discusses the relevant literature pertaining to the proposed model. The third section presents the methodology, including details about the dataset and details about conventional ML techniques. Details about the proposed DNN model have also been explained in detail. The fourth section presents the results and discussions, followed by conclusions in the last section.\n",
    "3 Methodology\n",
    "3.1 Pima Indians Diabetes Dataset Description\n",
    "The PIMA Indians Diabetes Dataset [7] contains 8 features as listed below.  \n",
    "\tPregnancy History: Number of times pregnant\n",
    "\tGlucose Levels: Plasma glucose concentration in a 2-hour glucose tolerance test\n",
    "\tBlood Pressure: Diastolic blood pressure (mm Hg)\n",
    "\tSkin Thickness: Triceps skin fold thickness (mm)\n",
    "\tInsulin: 2-hour serum insulin (mu/U/ml)\n",
    "\tBMI: Body Mass Index\n",
    "\tDiabetic Pedigree Function: Scores the likelihood of diabetes using family history.\n",
    "\tAge\n",
    "There are more instances of non-diabetic (labelled 0) individuals (65%) than diabetic (labelled 1) ones (35%). Sample data from the Pima Indians Dataset has been shown in Table 1. A summary of the dataset (count, mean, standard deviation, minimum/maximum value, 25/50/75%) is presented in Table 2 and is self-explanatory.\n",
    "3.2 Exploratory Data Analysis\n",
    "Exploratory Data Analysis (EDA) is an important initial step involving analyzing the dataset to understand its key relationships and characteristics. EDA aims to generate insights and hypotheses through different graphs, charts, and statistical summaries. During the process of EDA, it is important to carefully consider missing values, outliers, and anomalies, as they can significantly affect the accuracy of the analysis results. Imputation techniques such as using mean/median values or removing the records can be used to address missing values.\n",
    "\n",
    "Outliers and anomalies can be identified using statistical measures such as standard deviation or interquartile range and can be addressed using techniques such as truncation or winsorization. It is imperative to handle these issues carefully to ensure that the analysis results are accurate and reliable. EDA is particularly useful in identifying potential errors and inconsistencies in the data, which can be corrected before further analysis.\n",
    "In this paper, we analyzed how the likelihood of diabetes is affected by multiple features using EDA. In this EDA, we analyse multivariate data to find relationships between features. Visualizations and insights found during the EDA have been presented in Figures 1, 2 and 3. It can be noted that in the figures, an outcome of 0 represents non-diabetic people, and an outcome of 1 represents diabetic people.\n",
    " \n",
    "Figure 1 shows when a person’s age is less than 30, and their blood glucose level is less than 120 mg/dL or their number of pregnancies is less than 6, they are less likely to have diabetes.\t\n",
    "Figure 2 shows when a person’s blood glucose level is less than 105 mg/dL, and their BMI less than 30 or blood pressure is less than 80 mmHg, they are less prone to diabetes. \n",
    "Figure 3 shows when a person’s BMI is less than 30 and their skin thickness is less than 20 mm, they are less susceptible to diabetes.\n",
    "3.1.3 Data Preparation\n",
    "One of the biggest challenges with the PIMA Indians Diabetes Dataset is the presence of missing data in the Glucose, Blood Pressure, Skin Thickness, Insulin and BMI features. To combat this issue, this paper uses the following steps:\n",
    "\tStep 1: Remove outlier data points using Z Score and Inter Quartile Range Method.\n",
    "\tStep 2: Replace missing values (having value zero) with the mean value of the feature.\n",
    "\tStep 3: Check the values of all features after adjustments, to ensure the completeness of data.\n",
    "An outlier is an observation that deviates significantly from the rest of the dataset. These observations can have a significant impact while training ML models, leading to inaccurate results and predictions. By removing outliers, we can better understand the underlying patterns in our data and gather meaningful insights from it. The dataset’s outliers have been visualized using a box plot in Figure 4. This paper uses the Z-Score and Inter Quartile Range methods for removing these outliers from the dataset.\n",
    "The Z-Score method is a type of statistical technique, used for identifying and removing outliers from the dataset. It is based on the Z-Score, which represents the number of standard deviations that the observation is from the mean. The formula for the Z-Score is given by Equation 1, where x is the observation, \\mu is the feature’s mean value and \\sigma is the standard deviation of the feature. In this paper, we have established a threshold value of 3 for Z-Score, above which the observation will be removed from the dataset.\n",
    "The Inter Quartile Range (IQR) method is another outlier removal technique, which works by calculating the range between the 25th and 75th percentiles of the data, also known as the interquartile range. This technique is very useful in identifying outliers in non-normal distributions, as it is less sensitive to extreme values than the Z-Score method. Equation 2 describes the function R(x), which uses the IQR method for outlier rejection.\n",
    "where x is the feature vector, Q1 is the first quartile, Q3 is the third quartile, and IQR is the interquartile range of the attributes. \n",
    "This paper employs the Z-Score method first, and then uses the IQR method on the remaining records. After outlier removal, the number of records in the dataset comes down to 619. The missing values are imputed by their feature’s mean value. Imputation with the mean is useful due to the effective imputation of continous data without the introduction of outliers.\n",
    " \n",
    "3.1.4 Data Standardization\n",
    "After the above process, it is essential to standardize the dataset as it is a common requirement for various machine learning estimators to perform well for the given dataset. This study utilized the Min Max Scaler standardization algorithm, which scales each feature to the range [0,1]. The formula used by this algorithm is described in Equation 3. The dataset after standardization has been presented in Table 3.\n",
    "where X is the input feature, Xmin and Xmax are the minimum and maximum values of the feature.\n",
    "3.3 Proposed Method\n",
    "An Artificial Neural Network (ANN) is a computational model that draws inspiration from the structure and function of biological neurons. Just like the human brain, an ANN consists of many connected nodes, or artificial neurons, that work together to process information. ANN's typically include one or more hidden layers, where the neurons process data and pass it on to the next layer. Each neuron has an activation function, which helps to determine the output of that neuron. The output from the artificial neurons can be used for classification or prediction tasks, among others.\n",
    "A dense neural network is a particular kind of artificial neural network, in which all the neurons are connected from one layer to the next layer.  Each connection between neurons has a corresponding weight, which determines the strength of the connection [29].\n",
    "Each neuron in a neural network has an activation function, which is used to determine the importance of an output from the neuron. This paper uses the Parametric Rectified Linear Unit (PReLU) and Sigmoid activation function. PReLU is a modification of the Rectified Linear Unit (ReLU) activation which sets all negative values to zero and leaves positive values unchanged. PReLU introduces a parameter that allows it to adjust the slope of the function for negative inputs. This means that PReLU can learn the appropriate slope for negative inputs during training. The equation of PReLU is described in Equation 4, where α is the learnable parameter that determines the slope for negative inputs and x is the input feature.\n",
    "\n",
    "A mathematical function called the sigmoid activation converts any input value to a number between 0 and 1 has been used in the neural network. Additionally, because it is a non-linear function, neural networks may simulate intricate connections between inputs and outputs. The function has been described in Equation 5, where x is the input feature.\n",
    "We propose utilizing a deep neural network for this prediction task, which comprises an input layer, two dense layers utilizing a PReLU activation function, and a final output layer utilizing a Sigmoid activation function. The input layer contains 8 neurons, the first dense layer contains 128 neurons, the second dense layer contains 64 neurons, and the output layer contains one neuron. The overall architecture of the neural network can be found in Figure 5. A flowchart of our proposed method has been presented in Figure 6.\n",
    "\n",
    "The proposed neural network has been trained with the Binary Crossentropy Loss Function, which is a model metric aimed at tracking the performance of the classification model. It penalizes the model if the predicted probability diverges from the actual label. The formula for the loss function is described by Equation 6, where y_i represents the actual class and log(P(y_i)) is the probability of that class. \n",
    "The DNN uses the Adam Optimizer for finding an optimal learning rate. Adaptive Moment Estimation (Adam) is a gradient-based optimization algorithm, which is an extension of the Stochastic Gradient Descent (SGD) optimizer. Adam uses estimates of the first and second estimates of the moments, to compute adaptive learning rates for each parameter. So, it allows the optimizer to adjust its learning rate optimally, for faster convergence and improved generalization performance. Adam is often the default choice for optimizing neural networks, due to its performance and ease of use.\n",
    "3.4 Performance Evaluation\n",
    "To evaluate different models, we will be using the Accuracy, Precision, Recall, and F1 metrics. Accuracy can be defined as the percentage of correct predictions done by the model. It can also be defined as the ratio between the sum of true positives and true negatives to the count of the entire dataset and has been described in Equation 7. Precision refers to the proportion of positive samples that are accurately classified out of all positive samples that were classified, as described in Equation 8.\n",
    "On the other hand, recall is the ratio of correctly identified positive samples to the total number of actual positive samples in the dataset, as described in Equation 9. It evaluates the model's ability to detect all positive samples. The recall measures the model's ability to detect positive samples. The F1 score is the harmonic mean of precision and recall and has been described in Equation 10. It is a composite statistic that takes into account both recall and accuracy to provide a single number that summarizes the overall effectiveness of the model. Better performance is indicated by a higher F1 score, which has a maximum score of 1 and a minimum score of 0.\n",
    "where α = True Positives, β = False Positives, γ = True Negatives and δ = False Negatives\n",
    "4 Results\n",
    "In this paper, we compared the performance of five classification algorithms (Gaussian Naïve Bayes, Logistic Regression, KNN, SVM and DNN) in predicting diabetes using the PIMA dataset. The dataset has been split into 70% training data and 30% testing data is used for model evaluation. It has been trained for 30 epochs, with a batch size of 32 and validation split of 30%.\n",
    "Our results show that the DNN outperformed the other methods, achieving the highest accuracy of 81.72% and highest F1 Score of 0.6304. The second-best method was Logistic Regression, with an accuracy of 80.10% and the highest precision score of 0.7666. The SVM classifier achieved the highest recall (0.6037) and had an accuracy score of 72.58%. KNN achieved an accuracy score of 79.56%, while Gaussian Naïve Bayes had an accuracy of 77.95%. The results have been tabulated in Table 4 and a visualization is shown in Figure 7.\n",
    "\n",
    "The superior performance of DNN can be attributed to its ability to learn complex and nonlinear relationships between features and target variables. DNN can automatically extract high-level features from raw input data and use them to make accurate predictions. In contrast, the other methods we tested rely on linear relationships between features and target variables, which may not be sufficient for capturing the complexity of the PIMA dataset.\n",
    "5 Conclusion\n",
    "This study compares the performance of five classification algorithms in predicting diabetes using the PIMA dataset. Our findings suggest that DNNs outperform other algorithms in terms of accuracy and F1-score metrics. Specifically, the DNN achieved an accuracy of 81.72% and an F1-score of 0.6304, demonstrating its potential as a valuable tool for predicting diabetes in the PIMA Indian population.\n",
    "While DNNs show promising results in healthcare, it is crucial to address the ethical implications of using predictive models as well as ensure that these models do not perpetuate biases or discrimination. Our study contributes to the growing body of research on the application of ML techniques in healthcare and provides evidence for the potential of DNNs in diabetes prediction. However, further optimization of the DNN model through hyperparameter tuning and additional training is necessary to improve its accuracy. Additionally, future research could explore the use of DNNs in other healthcare domains and investigate the impact of such models on clinical decision-making and patient outcomes.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_paper2 = \"\"\"\n",
    "Palliative Care\n",
    "\n",
    "“Death is a natural part of life.” – Yoda\n",
    "\n",
    "Medical advances have allowed humans to live increasingly longer lives, even in the face of serious illness and disease.  Those who are facing a life-threatening illness are in need of a multi-faceted approach in order to ensure their continued life, however long or short it is, will be of good quality.  Palliative care, as defined by the World Health Organization, is “an approach that improves the quality of life of patients and their families facing the problems associated with life-threatening illness” (World Health Organization, 2004).  Unlike end-of-life care which deals with issues surrounding the very end of an individual’s life, palliative care seeks to improve quality of life for individuals and families facing life-threatening and terminal illness from onset through to the family’s bereavement. This is done using an holistic approach with focus on easing physical, psychosocial, and spiritual discomfort.  Palliative care is a caring, not a curing, approach that is provided regardless of the age of the patient.  \n",
    "The history of palliative care begins with hospice .  Hospice, like most other social support, was first provided by religious groups, but has gradually become an important part of the healthcare system.  The first hospices, St. Joseph’s and St. Christopher’s Hospice, were started in England in 1967 by a woman named Cicely Saunders who is considered the founder of the hospice movement (Beresford, Adshead, Croft, 2007).  Saunders idea made it to the United States where, after nearly two decades, legislation was passed approving federal funding for hospice programs.  Palliative care grew from the hospice setting as it was realized that patients and their families displayed a need for a more holistic treatment plan.  Throughout the short time since its beginning, palliative and end-of-life care have made great progress in obtaining support from the government and the public in the effort to provide better care for those with terminal illness.  In 2007, the Worldwide Palliative Care Alliance was formed; one can ascertain that its creation is in response to the growing number of chronic illnesses, such as cancer and HIV/AIDs, and medical advances that are extending life spans.  \n",
    "While many different professions and disciplines are involved in providing palliative care, social workers have a special role to play in this area. First, social workers aid in the direct provision of services by working closely with the patient and families to obtain psychosocial, spiritual, and financial guidance during the span of the illness.  In addition, the social worker also has the means to raise awareness and improve the quality of services offered.  Because of social workers’ often very direct contact with patients and their families during times of need, they are able to witness first-hand the areas of strength and weakness within the caring system.  Armed with this knowledge, a social worker serves the additional purpose of “changing the society”  (Morales, Sheafor, Scott, 2007).  Although there are a growing number of organizations – government and otherwise – that are devoting research funding to this topic, social workers are trained to be action-oriented in achieving change in society to assist vulnerable populations; they are not merely doing the research for results/confirmation sake.  Social workers are able to create discussion in society that will have the possibility to lead to policy/law creation and change.\n",
    "   The World Health Organization, in their publication “The Solid Facts” about palliative care, mentions multiple areas of need, such as cultural sensitivity, reaching economically repressed populations, and training “across all settings” (World Health Organization, 2004).  Social workers are adept at working with culturally diverse populations which allows them to help healthcare teams to cater to patients’ specific needs without interfering with their cultural beliefs and values.  In addition to working with culturally diverse populations, social workers are also familiar with assisting economically-challenged individuals and families who may not know palliative care services are available to them, or do not know how to go about obtaining them.  Currently, Medicare and most insurance companies cover palliative care costs (Palliative Care, 2010); however, financially-strained families may need additional assistance for things such as funeral costs and dealing with loss of income when a family member passes away.  The State of New York recently enacted a bill called the New York Palliative Care Information Act which requires physicians to tell their terminally ill patients about palliative care options (Brody, 2010).  While the law is an important step to palliative care being more widely discussed and available, the article mentions the same need for training that the World Health Organization identified.  Social workers have an ethical obligation to obtain such training and knowledge if they are going to work in such a setting, and they could help and encourage others in the healthcare world to obtain such training.\n",
    "Social workers, by necessity through their profession, have education and training in working with diverse populations on an individual, family, community, and policy-making level; therefore, they hold a unique and important position within this growing, specialized field.   The National Association of Social Workers has published Standards for Palliative and End-of-Life Care as a guide for social workers within this field.  Each standard listed, while tailored to show its relationship to palliative and end-of-life care, encompasses all facets expected of a social worker in their chosen field.  Topics such as ethics, knowledge, assessment, treatment planning, empowerment, teamwork, cultural competence, leadership, and training are all within the realm of social workers vast skill-set.  Through this broad scope of standards, social workers are able to step into their role within a palliative care setting to assist clients (individuals and/or their families) and other healthcare practitioners, with a variety of issues in which they are well-versed.  \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "### System:\n",
    "You are an assistant which summarizes news articles and research papers.\n",
    "You should ensure that all summaries are atleast 100 words.\n",
    "\n",
    "### User:\n",
    "Summarize the following text:\n",
    "\"{text}\"\n",
    "\n",
    "### Response: \n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter()\n",
    "texts = text_splitter.split_text(research_paper2)\n",
    "docs = [Document(page_content=t) for t in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary_chain = load_summarize_chain(llm, chain_type=\"map_reduce\", map_prompt=prompt, combine_prompt=prompt)\n",
    "summary_chain = load_summarize_chain(llm, chain_type='stuff', prompt=prompt)\n",
    "# summarize_document_chain = AnalyzeDocumentChain(combine_docs_chain=summary_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/aadarsh/src/llm-sih-test/test-llm.ipynb Cell 9\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/aadarsh/src/llm-sih-test/test-llm.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/aadarsh/src/llm-sih-test/test-llm.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/aadarsh/src/llm-sih-test/test-llm.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m (summary_chain\u001b[39m.\u001b[39;49mrun(docs))\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/aadarsh/src/llm-sih-test/test-llm.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m--- \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m seconds ---\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time))\n",
      "File \u001b[0;32m~/src/llm-sih-test/myenv/lib/python3.8/site-packages/langchain/chains/base.py:487\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    486\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 487\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m], callbacks\u001b[39m=\u001b[39;49mcallbacks, tags\u001b[39m=\u001b[39;49mtags, metadata\u001b[39m=\u001b[39;49mmetadata)[\n\u001b[1;32m    488\u001b[0m         _output_key\n\u001b[1;32m    489\u001b[0m     ]\n\u001b[1;32m    491\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    492\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks, tags\u001b[39m=\u001b[39mtags, metadata\u001b[39m=\u001b[39mmetadata)[\n\u001b[1;32m    493\u001b[0m         _output_key\n\u001b[1;32m    494\u001b[0m     ]\n",
      "File \u001b[0;32m~/src/llm-sih-test/myenv/lib/python3.8/site-packages/langchain/chains/base.py:292\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    291\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 292\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    293\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    294\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    295\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    296\u001b[0m )\n",
      "File \u001b[0;32m~/src/llm-sih-test/myenv/lib/python3.8/site-packages/langchain/chains/base.py:286\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    279\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    280\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[1;32m    281\u001b[0m     inputs,\n\u001b[1;32m    282\u001b[0m     name\u001b[39m=\u001b[39mrun_name,\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    284\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    285\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 286\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    287\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    288\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    289\u001b[0m     )\n\u001b[1;32m    290\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    291\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/src/llm-sih-test/myenv/lib/python3.8/site-packages/langchain/chains/combine_documents/base.py:105\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[1;32m    104\u001b[0m other_keys \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key}\n\u001b[0;32m--> 105\u001b[0m output, extra_return_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcombine_docs(\n\u001b[1;32m    106\u001b[0m     docs, callbacks\u001b[39m=\u001b[39;49m_run_manager\u001b[39m.\u001b[39;49mget_child(), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mother_keys\n\u001b[1;32m    107\u001b[0m )\n\u001b[1;32m    108\u001b[0m extra_return_dict[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key] \u001b[39m=\u001b[39m output\n\u001b[1;32m    109\u001b[0m \u001b[39mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[0;32m~/src/llm-sih-test/myenv/lib/python3.8/site-packages/langchain/chains/combine_documents/stuff.py:171\u001b[0m, in \u001b[0;36mStuffDocumentsChain.combine_docs\u001b[0;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_inputs(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    170\u001b[0m \u001b[39m# Call predict on the LLM.\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm_chain\u001b[39m.\u001b[39;49mpredict(callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs), {}\n",
      "File \u001b[0;32m~/src/llm-sih-test/myenv/lib/python3.8/site-packages/langchain/chains/llm.py:255\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, callbacks: Callbacks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    241\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \n\u001b[1;32m    243\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[39m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs, callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key]\n",
      "File \u001b[0;32m~/src/llm-sih-test/myenv/lib/python3.8/site-packages/langchain/chains/base.py:292\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    291\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 292\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    293\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    294\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    295\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    296\u001b[0m )\n",
      "File \u001b[0;32m~/src/llm-sih-test/myenv/lib/python3.8/site-packages/langchain/chains/base.py:286\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    279\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    280\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[1;32m    281\u001b[0m     inputs,\n\u001b[1;32m    282\u001b[0m     name\u001b[39m=\u001b[39mrun_name,\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    284\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    285\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 286\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    287\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    288\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    289\u001b[0m     )\n\u001b[1;32m    290\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    291\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/src/llm-sih-test/myenv/lib/python3.8/site-packages/langchain/chains/llm.py:91\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\n\u001b[1;32m     87\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     88\u001b[0m     inputs: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[1;32m     89\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     90\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m---> 91\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate([inputs], run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m     92\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_outputs(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/src/llm-sih-test/myenv/lib/python3.8/site-packages/langchain/chains/llm.py:101\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m    100\u001b[0m prompts, stop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_prompts(input_list, run_manager\u001b[39m=\u001b[39mrun_manager)\n\u001b[0;32m--> 101\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[1;32m    102\u001b[0m     prompts,\n\u001b[1;32m    103\u001b[0m     stop,\n\u001b[1;32m    104\u001b[0m     callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    105\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm_kwargs,\n\u001b[1;32m    106\u001b[0m )\n",
      "File \u001b[0;32m~/src/llm-sih-test/myenv/lib/python3.8/site-packages/langchain/llms/base.py:486\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[1;32m    479\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    480\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    484\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    485\u001b[0m     prompt_strings \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_string() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[0;32m--> 486\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_strings, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/src/llm-sih-test/myenv/lib/python3.8/site-packages/langchain/llms/base.py:621\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    613\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    614\u001b[0m         )\n\u001b[1;32m    615\u001b[0m     run_managers \u001b[39m=\u001b[39m [\n\u001b[1;32m    616\u001b[0m         callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[1;32m    617\u001b[0m             dumpd(\u001b[39mself\u001b[39m), [prompt], invocation_params\u001b[39m=\u001b[39mparams, options\u001b[39m=\u001b[39moptions\n\u001b[1;32m    618\u001b[0m         )[\u001b[39m0\u001b[39m]\n\u001b[1;32m    619\u001b[0m         \u001b[39mfor\u001b[39;00m callback_manager, prompt \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(callback_managers, prompts)\n\u001b[1;32m    620\u001b[0m     ]\n\u001b[0;32m--> 621\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_helper(\n\u001b[1;32m    622\u001b[0m         prompts, stop, run_managers, \u001b[39mbool\u001b[39;49m(new_arg_supported), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    623\u001b[0m     )\n\u001b[1;32m    624\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing_prompts) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/src/llm-sih-test/myenv/lib/python3.8/site-packages/langchain/llms/base.py:523\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n\u001b[1;32m    522\u001b[0m         run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 523\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    524\u001b[0m flattened_outputs \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m    525\u001b[0m \u001b[39mfor\u001b[39;00m manager, flattened_output \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/src/llm-sih-test/myenv/lib/python3.8/site-packages/langchain/llms/base.py:510\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_generate_helper\u001b[39m(\n\u001b[1;32m    501\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    502\u001b[0m     prompts: List[\u001b[39mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    507\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    508\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    509\u001b[0m         output \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 510\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[1;32m    511\u001b[0m                 prompts,\n\u001b[1;32m    512\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    513\u001b[0m                 \u001b[39m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    514\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[\u001b[39m0\u001b[39;49m] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    515\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    516\u001b[0m             )\n\u001b[1;32m    517\u001b[0m             \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    518\u001b[0m             \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop)\n\u001b[1;32m    519\u001b[0m         )\n\u001b[1;32m    520\u001b[0m     \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    521\u001b[0m         \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/src/llm-sih-test/myenv/lib/python3.8/site-packages/langchain/llms/base.py:1000\u001b[0m, in \u001b[0;36mLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    997\u001b[0m new_arg_supported \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39msignature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    998\u001b[0m \u001b[39mfor\u001b[39;00m prompt \u001b[39min\u001b[39;00m prompts:\n\u001b[1;32m    999\u001b[0m     text \u001b[39m=\u001b[39m (\n\u001b[0;32m-> 1000\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(prompt, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1001\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m   1002\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(prompt, stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1003\u001b[0m     )\n\u001b[1;32m   1004\u001b[0m     generations\u001b[39m.\u001b[39mappend([Generation(text\u001b[39m=\u001b[39mtext)])\n\u001b[1;32m   1005\u001b[0m \u001b[39mreturn\u001b[39;00m LLMResult(generations\u001b[39m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m~/src/llm-sih-test/myenv/lib/python3.8/site-packages/langchain/llms/llamacpp.py:291\u001b[0m, in \u001b[0;36mLlamaCpp._call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstreaming:\n\u001b[1;32m    287\u001b[0m     \u001b[39m# If streaming is enabled, we use the stream\u001b[39;00m\n\u001b[1;32m    288\u001b[0m     \u001b[39m# method that yields as they are generated\u001b[39;00m\n\u001b[1;32m    289\u001b[0m     \u001b[39m# and return the combined strings from the first choices's text:\u001b[39;00m\n\u001b[1;32m    290\u001b[0m     combined_text_output \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 291\u001b[0m     \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stream(\n\u001b[1;32m    292\u001b[0m         prompt\u001b[39m=\u001b[39mprompt,\n\u001b[1;32m    293\u001b[0m         stop\u001b[39m=\u001b[39mstop,\n\u001b[1;32m    294\u001b[0m         run_manager\u001b[39m=\u001b[39mrun_manager,\n\u001b[1;32m    295\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    296\u001b[0m     ):\n\u001b[1;32m    297\u001b[0m         combined_text_output \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m chunk\u001b[39m.\u001b[39mtext\n\u001b[1;32m    298\u001b[0m     \u001b[39mreturn\u001b[39;00m combined_text_output\n",
      "File \u001b[0;32m~/src/llm-sih-test/myenv/lib/python3.8/site-packages/langchain/llms/llamacpp.py:344\u001b[0m, in \u001b[0;36mLlamaCpp._stream\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m params \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_parameters(stop), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs}\n\u001b[1;32m    343\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient(prompt\u001b[39m=\u001b[39mprompt, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m--> 344\u001b[0m \u001b[39mfor\u001b[39;00m part \u001b[39min\u001b[39;00m result:\n\u001b[1;32m    345\u001b[0m     logprobs \u001b[39m=\u001b[39m part[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mlogprobs\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    346\u001b[0m     chunk \u001b[39m=\u001b[39m GenerationChunk(\n\u001b[1;32m    347\u001b[0m         text\u001b[39m=\u001b[39mpart[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    348\u001b[0m         generation_info\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mlogprobs\u001b[39m\u001b[39m\"\u001b[39m: logprobs},\n\u001b[1;32m    349\u001b[0m     )\n",
      "File \u001b[0;32m~/src/llm-sih-test/myenv/lib/python3.8/site-packages/llama_cpp/llama.py:945\u001b[0m, in \u001b[0;36mLlama._create_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar)\u001b[0m\n\u001b[1;32m    943\u001b[0m finish_reason \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlength\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    944\u001b[0m multibyte_fix \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 945\u001b[0m \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate(\n\u001b[1;32m    946\u001b[0m     prompt_tokens,\n\u001b[1;32m    947\u001b[0m     top_k\u001b[39m=\u001b[39mtop_k,\n\u001b[1;32m    948\u001b[0m     top_p\u001b[39m=\u001b[39mtop_p,\n\u001b[1;32m    949\u001b[0m     temp\u001b[39m=\u001b[39mtemperature,\n\u001b[1;32m    950\u001b[0m     tfs_z\u001b[39m=\u001b[39mtfs_z,\n\u001b[1;32m    951\u001b[0m     mirostat_mode\u001b[39m=\u001b[39mmirostat_mode,\n\u001b[1;32m    952\u001b[0m     mirostat_tau\u001b[39m=\u001b[39mmirostat_tau,\n\u001b[1;32m    953\u001b[0m     mirostat_eta\u001b[39m=\u001b[39mmirostat_eta,\n\u001b[1;32m    954\u001b[0m     frequency_penalty\u001b[39m=\u001b[39mfrequency_penalty,\n\u001b[1;32m    955\u001b[0m     presence_penalty\u001b[39m=\u001b[39mpresence_penalty,\n\u001b[1;32m    956\u001b[0m     repeat_penalty\u001b[39m=\u001b[39mrepeat_penalty,\n\u001b[1;32m    957\u001b[0m     stopping_criteria\u001b[39m=\u001b[39mstopping_criteria,\n\u001b[1;32m    958\u001b[0m     logits_processor\u001b[39m=\u001b[39mlogits_processor,\n\u001b[1;32m    959\u001b[0m     grammar\u001b[39m=\u001b[39mgrammar,\n\u001b[1;32m    960\u001b[0m ):\n\u001b[1;32m    961\u001b[0m     \u001b[39mif\u001b[39;00m token \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_token_eos:\n\u001b[1;32m    962\u001b[0m         text \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdetokenize(completion_tokens)\n",
      "File \u001b[0;32m~/src/llm-sih-test/myenv/lib/python3.8/site-packages/llama_cpp/llama.py:765\u001b[0m, in \u001b[0;36mLlama.generate\u001b[0;34m(self, tokens, top_k, top_p, temp, repeat_penalty, reset, frequency_penalty, presence_penalty, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, logits_processor, stopping_criteria, grammar)\u001b[0m\n\u001b[1;32m    762\u001b[0m     grammar\u001b[39m.\u001b[39mreset()\n\u001b[1;32m    764\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meval(tokens)\n\u001b[1;32m    766\u001b[0m     token \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample(\n\u001b[1;32m    767\u001b[0m         top_k\u001b[39m=\u001b[39mtop_k,\n\u001b[1;32m    768\u001b[0m         top_p\u001b[39m=\u001b[39mtop_p,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    778\u001b[0m         grammar\u001b[39m=\u001b[39mgrammar,\n\u001b[1;32m    779\u001b[0m     )\n\u001b[1;32m    780\u001b[0m     \u001b[39mif\u001b[39;00m stopping_criteria \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m stopping_criteria(\n\u001b[1;32m    781\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_ids\u001b[39m.\u001b[39mtolist(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_scores[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m    782\u001b[0m     ):\n",
      "File \u001b[0;32m~/src/llm-sih-test/myenv/lib/python3.8/site-packages/llama_cpp/llama.py:484\u001b[0m, in \u001b[0;36mLlama.eval\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    482\u001b[0m n_past \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(n_ctx \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(batch), \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_ids))\n\u001b[1;32m    483\u001b[0m n_tokens \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(batch)\n\u001b[0;32m--> 484\u001b[0m return_code \u001b[39m=\u001b[39m llama_cpp\u001b[39m.\u001b[39;49mllama_eval(\n\u001b[1;32m    485\u001b[0m     ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mctx,\n\u001b[1;32m    486\u001b[0m     tokens\u001b[39m=\u001b[39;49m(llama_cpp\u001b[39m.\u001b[39;49mllama_token \u001b[39m*\u001b[39;49m \u001b[39mlen\u001b[39;49m(batch))(\u001b[39m*\u001b[39;49mbatch),\n\u001b[1;32m    487\u001b[0m     n_tokens\u001b[39m=\u001b[39;49mllama_cpp\u001b[39m.\u001b[39;49mc_int(n_tokens),\n\u001b[1;32m    488\u001b[0m     n_past\u001b[39m=\u001b[39;49mllama_cpp\u001b[39m.\u001b[39;49mc_int(n_past),\n\u001b[1;32m    489\u001b[0m     n_threads\u001b[39m=\u001b[39;49mllama_cpp\u001b[39m.\u001b[39;49mc_int(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_threads),\n\u001b[1;32m    490\u001b[0m )\n\u001b[1;32m    491\u001b[0m \u001b[39mif\u001b[39;00m return_code \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    492\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mllama_eval returned \u001b[39m\u001b[39m{\u001b[39;00mreturn_code\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/src/llm-sih-test/myenv/lib/python3.8/site-packages/llama_cpp/llama_cpp.py:808\u001b[0m, in \u001b[0;36mllama_eval\u001b[0;34m(ctx, tokens, n_tokens, n_past, n_threads)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mllama_eval\u001b[39m(\n\u001b[1;32m    802\u001b[0m     ctx: llama_context_p,\n\u001b[1;32m    803\u001b[0m     tokens,  \u001b[39m# type: Array[llama_token]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    806\u001b[0m     n_threads: c_int,\n\u001b[1;32m    807\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[0;32m--> 808\u001b[0m     \u001b[39mreturn\u001b[39;00m _lib\u001b[39m.\u001b[39;49mllama_eval(ctx, tokens, n_tokens, n_past, n_threads)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "print (summary_chain.run(docs))\n",
    "print (\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orca-mini Map-Reduce Summarization\n",
    "\"\"\"\n",
    "This paper proposes a novel approach to classify Pima Indian women as either diabetic or non-diabetic using an Artificial Neural Network (ANN) with a dense neural network architecture. The proposed method uses the PReLU activation function and Sigmoid activation function for the output layer, which is trained on the dataset of features and their corresponding outcomes. The performance of the model is evaluated using metrics such as accuracy, precision, recall, and F1 score. The results show that the proposed ANN outperformed other methods, achieving the highest accuracy of 81.72% and highest F1 Score of 0.6304. However, it is crucial to address ethical concerns and ensure that these models do not perpetuate biases or discrimination.\n",
    "--- 1213.4731895923615 seconds ---\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
